{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "#@title LICENSE\n",
        "\n",
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "# Use Vertex AI Extensions with a Custom Extension\n",
        "\n",
        "## Overview\n",
        "\n",
        "\n",
        "Vertex AI Extensions is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf. You can use pre-built or third-party extensions in Vertex AI Extensions.\n",
        "\n",
        "Learn more about [Vertex AI Extensions](https://cloud.google.com/vertex-ai/docs/generative-ai/extensions/private/overview).\n",
        "\n",
        "This notebook provides a simple getting started experience for the Vertex AI Extensions framework. This guide assumes that you are familiar with the Vertex AI Python SDK, [LangChain](https://python.langchain.com/docs/get_started/introduction), [OpenAPI specification](https://swagger.io/specification/), and [Cloud Run](https://cloud.google.com/run/docs).\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to create an extension service backend on Cloud Run, register the extension with Vertex, and then use the extension in an application.\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Creating a simple service running on Cloud Run\n",
        "- Creating an OpenAPI 3.1 YAML file for the Cloud Run service\n",
        "- Registering the service as an extension with Vertex AI\n",
        "- Using the extension to respond to user queries\n",
        "- Integrate LangChain into the reasoning for an extension\n",
        "\n",
        "### Additional Information\n",
        "\n",
        "This tutorial uses the following Google Cloud services and resources:\n",
        "\n",
        "- Vertex AI Extensions\n",
        "- Cloud Run\n",
        "\n",
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2OYMHXO8gjT"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "You must authenticate to Google Cloud to access the pre-release version of the Python SDK and the Vertex AI Extensions feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Installation\n",
        "\n",
        "This tutorial requires a pre-release version of the Python SDK for Vertex AI. You must be logged in with credentials that are registered for the Vertex AI Extensions Private Preview.\n",
        "\n",
        "Run the following command to download the library as a wheel from a Cloud Storage bucket:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfhvjtxGcOfm"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://vertex_sdk_private_releases/llm_extension/google_cloud_aiplatform-1.39.dev20231219+llm.extension-py2.py3-none-any.whl ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNZlGMiqcOfm"
      },
      "source": [
        "Then, install the following packages required to execute this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1MlayQHghLz"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall --quiet google_cloud_aiplatform-1.39.dev20231219+llm.extension-py2.py3-none-any.whl\n",
        "!pip install --upgrade --quiet \"langchain==0.0.331\" \\\n",
        "\"openapi-schema-pydantic==1.2.4\" \\\n",
        "\"openapi-pydantic==0.3.2\" \\\n",
        "\"google-cloud-storage\" \\\n",
        "\"shapely<2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5RDjT_98gjU"
      },
      "source": [
        "Restart the kernel after installing packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "1. Your project must also be allowlisted for the Vertex AI Extension Private Preview.\n",
        "1. This notebook requires that you have the following permissions for your GCP project:\n",
        "- `roles/aiplatform.user`\n",
        "\n",
        "### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1",
        "outputId": "a0480caa-168a-4a2b-d9d4-6e9dde3d547d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkU1oUpBcOfo"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"your-bucket-name\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "extensions_prefix = \"extension\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "!gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import vertexai\n",
        "from google.cloud.aiplatform.private_preview import llm_extension\n",
        "from google.cloud import storage\n",
        "\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.tools import OpenAPISpec, APIOperation\n",
        "from langchain.chains import OpenAPIEndpointChain\n",
        "from langchain.requests import Requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABew50yughL0"
      },
      "outputs": [],
      "source": [
        "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkjLDSj2ghL0"
      },
      "source": [
        "## Creating an API backend service\n",
        "\n",
        "In this tutorial, you create a simple \"hello world\" service that runs on Cloud Run. This service returns \"hello\" in one of several languages, depending on the prompt sent from your extension (more on that later).\n",
        "\n",
        "This simple example does not demonstrate best practices for authentication. Authenticating to your service is covered later.\n",
        "\n",
        "**Note**: Your backend API service does not need to be hosted on Cloud Run.\n",
        "\n",
        "### Deploy the API service to Cloud Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JebL18KghL1"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"extension\"):\n",
        "    os.mkdir(\"extension\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIR46NIKghL1",
        "outputId": "95f0cb95-414b-4f96-a090-7bb914b89bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extension/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile extension/Dockerfile\n",
        "\n",
        "FROM python:3.11-slim\n",
        "\n",
        "ENV PYTHONUNBUFFERED True\n",
        "\n",
        "ENV APP_HOME /app\n",
        "WORKDIR $APP_HOME\n",
        "COPY . ./\n",
        "\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 extension:app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0u_OixcghL6",
        "outputId": "36a4d292-3954-4f58-e572-53bda5a5827c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extension/extension.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extension/extension.py\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route(\"/hello\", methods=[\"GET\"])\n",
        "def hello_world():\n",
        "    args = request.args\n",
        "    prompt = args.get(\"prompt\")\n",
        "    data = {\n",
        "      \"output\": \"hello\"\n",
        "    }\n",
        "    if prompt == \"French\":\n",
        "        data[\"output\"] = \"bonjour\"\n",
        "    elif prompt == \"Spanish\":\n",
        "        data[\"output\"] = \"hola\"\n",
        "\n",
        "    return jsonify(data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8080)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjNmQHEtghL6",
        "outputId": "cd6d0072-e832-4d5d-88d5-76b6f6b9a90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extension/requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile extension/requirements.txt\n",
        "Flask==2.3.3\n",
        "gunicorn==21.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUCFlFr1ghL6",
        "outputId": "3a78c30b-0469-46f9-f899-236c3d4b6486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extension/.dockerignore\n"
          ]
        }
      ],
      "source": [
        "%%writefile extension/.dockerignore\n",
        "Dockerfile\n",
        "README.md\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        "__pycache__\n",
        ".pytest_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raX4unoGuSEY"
      },
      "source": [
        "Next, you deploy the service to Cloud Run. However, you might need to log in once more to deploy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leotFWZxFUWd"
      },
      "outputs": [],
      "source": [
        "!gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kXRKtqtghL6",
        "outputId": "e2b53409-1dcd-43d6-f7dc-b44826ccc017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building and deploying...                                                      \n",
            "  . Uploading sources...                                                       \n",
            "  . Building Container...                                                      \n",
            "  . Creating Revision...                                                       \n",
            "  . Routing traffic...                                                         \n",
            "  . Setting IAM Policy...                                                      \n"
          ]
        }
      ],
      "source": [
        "!gcloud run deploy extension --region=us-central1 --allow-unauthenticated --source extension --no-user-output-enabled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOvybhjGcOfp"
      },
      "source": [
        "List the most recent Cloud Run service that was deployed, then you'll copy its URL to the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XpLElhYcOfp",
        "outputId": "7ebf6dc6-afad-4979-9def-c63552b1fb69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m✔\u001b[39;0m  extension                  us-central1  https://extension-r5gdynozbq-uc.a.run.app                  koverholt@cloudadvocacyorg.joonix.net  2023-12-19T23:24:57.635822Z\n"
          ]
        }
      ],
      "source": [
        "!gcloud run services list | sort -k 3 | head -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zccCypM1ghL6"
      },
      "outputs": [],
      "source": [
        "# @title Copy paste the output from the previous command here\n",
        "service_url = \"https://your-extension.run.app\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOmsbUSvghL7"
      },
      "source": [
        "### Create an OpenAPI spec\n",
        "\n",
        "Your Vertex Extension requires an OpenAPI 3.1 YAML file that defines routes, URL, HTTP methods, requests, and responses from your \"backend\" service. The following code creates a YAML file that you need to upload to your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_HhQerxghL7",
        "outputId": "9ab7bd6e-d8f8-4c85-9a9e-520c511c4736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "openapi: \"3.1.0\"\n",
            "info:\n",
            "  version: 1.0.0\n",
            "  title: hello_extensions\n",
            "  description: Learn to build Vertex AI extensions\n",
            "servers:\n",
            "  - url: https://extension-r5gdynozbq-uc.a.run.app\n",
            "paths:\n",
            "  /hello:\n",
            "    get:\n",
            "      operationId: say_hello\n",
            "      description: Prints 'hello' in the prompted language.\n",
            "      parameters:\n",
            "        - name: prompt\n",
            "          in: query\n",
            "          description: Any of the following strings--French, Spanish, English\n",
            "          required: true\n",
            "          schema:\n",
            "            type: string\n",
            "      responses:\n",
            "        '200':\n",
            "          description: Returns 'Hello' in the specified language.\n",
            "          content:\n",
            "            text/plain:\n",
            "              schema:\n",
            "                type: string\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"extension-api\"):\n",
        "    os.mkdir(\"extension-api\")\n",
        "\n",
        "openapi_yaml = f\"\"\"\n",
        "openapi: \"3.1.0\"\n",
        "info:\n",
        "  version: 1.0.0\n",
        "  title: hello_extensions\n",
        "  description: Learn to build Vertex AI extensions\n",
        "servers:\n",
        "  - url: {service_url}\n",
        "paths:\n",
        "  /hello:\n",
        "    get:\n",
        "      operationId: say_hello\n",
        "      description: Prints 'hello' in the prompted language.\n",
        "      parameters:\n",
        "        - name: prompt\n",
        "          in: query\n",
        "          description: Any of the following strings--French, Spanish, English\n",
        "          required: true\n",
        "          schema:\n",
        "            type: string\n",
        "      responses:\n",
        "        '200':\n",
        "          description: Returns 'Hello' in the specified language.\n",
        "          content:\n",
        "            text/plain:\n",
        "              schema:\n",
        "                type: string\n",
        "\"\"\"\n",
        "\n",
        "print(openapi_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjOGjGLighL7",
        "outputId": "cba3cbb2-84ed-4947-d5d8-306e32a25b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing 'openapi_yaml' (str) to file 'extension-api/extension.yaml'.\n"
          ]
        }
      ],
      "source": [
        "%store openapi_yaml >extension-api/extension.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bysxsgLghL7"
      },
      "source": [
        "Upload the OpenAPI YAML to your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5PWKGnmghL7"
      },
      "outputs": [],
      "source": [
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(BUCKET_NAME)\n",
        "blob_name = f\"{extensions_prefix}/extension.yaml\"\n",
        "blob = bucket.blob(blob_name)\n",
        "blob.upload_from_filename(\"extension-api/extension.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6DJJOt8ghL7"
      },
      "source": [
        "### Test the service locally using LangChain\n",
        "\n",
        "First, check that your service can accept simple HTTP `GET` requests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju2KQKc7rNqi",
        "outputId": "bee0eedb-b602-4500-837d-d3416445b12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://extension-r5gdynozbq-uc.a.run.app/hello?prompt=Spanish\n"
          ]
        }
      ],
      "source": [
        "url = f'{service_url}/hello?prompt=Spanish'\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82rwEauXghL8",
        "outputId": "b0add1cf-e751-42fc-ad7f-6a42706980fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status Code: 200, Content: {\"output\":\"hola\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "r = requests.get(url,\n",
        "                 headers={\n",
        "                    'Accept': 'application/json'\n",
        "                 })\n",
        "\n",
        "print(f\"Status Code: {r.status_code}, Content: {r.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4IfPzFHr4o5"
      },
      "source": [
        "Next, instantiate the Vertex AI LLM with LangChain. Try a simple, multi-step reasoning prompt first to ensure that it has loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIykgA-jr3nZ",
        "outputId": "3e593f25-6fb6-414f-9d34-c198dde06f27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Justin Bieber was born on March 1, 1994. The Super Bowl is held in February, so the Super Bowl that happened in the year Justin Bieber was born would have been Super Bowl XXVIII, which was held on January 30, 1994. The Dallas Cowboys won Super Bowl XXVIII.\\n\\nThe final answer is Dallas Cowboys'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm = VertexAI()\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUWL8SVsSbI"
      },
      "source": [
        "Now, create the OpenAPI chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D4c2GgmsUm-"
      },
      "outputs": [],
      "source": [
        "spec = OpenAPISpec.from_file(\"extension-api/extension.yaml\")\n",
        "operation = APIOperation.from_openapi_spec(spec, \"/hello\", \"get\")\n",
        "chain = OpenAPIEndpointChain.from_api_operation(\n",
        "    operation,\n",
        "    llm,\n",
        "    requests=Requests(),\n",
        "    verbose=True,\n",
        "    return_intermediate_steps=True,  # Return request and response text\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b-bDbQkspE8",
        "outputId": "501cee4f-d42f-4136-c828-c9707058612e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new OpenAPIEndpointChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new APIRequesterChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user's instructions.\n",
            "\n",
            "API_SCHEMA: ```typescript\n",
            "/* Prints 'hello' in the prompted language. */\n",
            "type say_hello = (_: {\n",
            "/* Any of the following strings--French, Spanish, English */\n",
            "\t\tprompt: string,\n",
            "}) => any;\n",
            "```\n",
            "\n",
            "USER_INSTRUCTIONS: \"Question: How do you say 'hello' in Spanish?\"\n",
            "\n",
            "Your arguments must be plain json provided in a markdown block:\n",
            "\n",
            "ARGS: ```json\n",
            "{valid json conforming to API_SCHEMA}\n",
            "```\n",
            "\n",
            "Example\n",
            "-----\n",
            "\n",
            "ARGS: ```json\n",
            "{\"foo\": \"bar\", \"baz\": {\"qux\": \"quux\"}}\n",
            "```\n",
            "\n",
            "The block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\n",
            "You MUST strictly comply to the types indicated by the provided schema, including all required args.\n",
            "\n",
            "If you don't have sufficient information to call the function due to things like requiring specific uuid's, you can reply with the following message:\n",
            "\n",
            "Message: ```text\n",
            "Concise response requesting the additional information that would make calling the function successful.\n",
            "```\n",
            "\n",
            "Begin\n",
            "-----\n",
            "ARGS:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/koverholt/miniforge3/lib/python3.11/site-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\"prompt\": \"Spanish\"}\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m{\"output\":\"hola\"}\n",
            "\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new APIResponderChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant trained to answer user queries from API responses.\n",
            "You attempted to call an API, which resulted in:\n",
            "API_RESPONSE: {\"output\":\"hola\"}\n",
            "\n",
            "\n",
            "USER_COMMENT: \"Question: How do you say 'hello' in Spanish?\"\n",
            "\n",
            "\n",
            "If the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\n",
            "Response: ```json\n",
            "{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}\n",
            "```\n",
            "\n",
            "Otherwise respond with the following markdown json block:\n",
            "Response Error: ```json\n",
            "{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}\n",
            "```\n",
            "\n",
            "You MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\n",
            "\n",
            "Begin:\n",
            "---\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/koverholt/miniforge3/lib/python3.11/site-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe Spanish word for 'hello' is 'hola'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "output = chain(\"Question: How do you say 'hello' in Spanish?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLkzvkdUghL8"
      },
      "source": [
        "## Creating and using a custom extension\n",
        "\n",
        "### Create the extension\n",
        "\n",
        "Now that you've set up the service to fulfill extension requests, you can create the extension itself.\n",
        "\n",
        "First, you'll define selection, invocation, and response examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgPF-bEhghL8"
      },
      "outputs": [],
      "source": [
        "# Include multiple selection, invocation, and response examples for best results.\n",
        "extension_selection_examples = [{\n",
        "    \"query\": \"I want to see 'hello' in Spanish\",\n",
        "    \"multi_steps\": [{\n",
        "        \"thought\": \"I should call translate_tool for this\",\n",
        "        \"extension_execution\": {\n",
        "          \"operation_id\": \"say_hello\",\n",
        "          \"extension_instruction\": \"return 'hola' from the prompt 'Spanish'\",\n",
        "          \"observation\": \"In Spanish, 'hello' is 'hola'\"\n",
        "        }\n",
        "      },\n",
        "      {\n",
        "        \"thought\": \"Since the observation was successful, I should respond back to the user with results\",\n",
        "        \"respond_to_user\": {}\n",
        "      }],\n",
        "}]\n",
        "\n",
        "extension_invocation_examples = [{\n",
        "      \"extension_instruction\": \"say 'hello' in Spanish\",\n",
        "      \"operation_id\": \"say_hello\",\n",
        "      \"thought\": \"Issue a sayHello operation request on hello_extension tool\",\n",
        "      \"operation_param\": \"{\\\"prompt\\\": \\\"Spanish\\\"}\",\n",
        "      \"parameters_mentioned\": [\"prompt\"]\n",
        "}]\n",
        "\n",
        "extension_response_examples = [{\n",
        "  \"operation_id\": \"say_hello\",\n",
        "  \"response_template\": \"{{ response }}\",\n",
        "}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYegdGQwcOfu"
      },
      "source": [
        "Then, you'll create your extension and include the examples from the previous cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZxADBm8cOfu",
        "outputId": "a4a5d0d9-68b7-462c-fc0f-be932df2e0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Extension\n",
            "Create Extension backing LRO: projects/964731510884/locations/us-central1/extensions/3698299719001309184/operations/2522298297096339456\n",
            "Extension created. Resource name: projects/964731510884/locations/us-central1/extensions/3698299719001309184\n",
            "To use this Extension in another session:\n",
            "extension = aiplatform.Extension('projects/964731510884/locations/us-central1/extensions/3698299719001309184')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<google.cloud.aiplatform.private_preview.llm_extension.extensions.Extension object at 0x14be81f10> \n",
              "resource name: projects/964731510884/locations/us-central1/extensions/3698299719001309184"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extension_translate = llm_extension.Extension.create(\n",
        "    display_name = \"Hello Extensions\",\n",
        "    description = \"Prints and translates hello in different languages\",\n",
        "    manifest = {\n",
        "        \"name\": \"translate_tool\",\n",
        "        \"description\": \"Prints and translates hello in different languages\",\n",
        "        \"api_spec\": {\n",
        "            \"open_api_gcs_uri\": f\"gs://{BUCKET_NAME}/{extensions_prefix}/extension.yaml\"\n",
        "        },\n",
        "        \"auth_config\": {\n",
        "            \"auth_type\": \"NO_AUTH\",\n",
        "        },\n",
        "        \"extension_selection_examples\": extension_selection_examples,\n",
        "        \"extension_invocation_examples\": extension_invocation_examples,\n",
        "        \"extension_response_examples\": extension_response_examples,\n",
        "    },\n",
        ")\n",
        "extension_translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO1R9sD-cOfu"
      },
      "source": [
        "Now that you've create your extension, let's confirm that it's registered:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gQPqLe5aNiK",
        "outputId": "bb6310b8-52da-4317-c6e3-9a9ac8142e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: projects/964731510884/locations/us-central1/extensions/3698299719001309184\n",
            "Display Name: Hello Extensions\n",
            "Description: Prints and translates words in different languages\n"
          ]
        }
      ],
      "source": [
        "print(\"Name:\", extension_translate.gca_resource.name)\n",
        "print(\"Display Name:\", extension_translate.display_name)\n",
        "print(\"Description:\", extension_translate.gca_resource.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiGFoRKQcOfu"
      },
      "source": [
        "And you can test the functionality of the extension by executing it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhFc0WewcOfu",
        "outputId": "443b085f-cadb-4d7b-a436-f36647891fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'output': 'hola'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extension_translate.execute(\"say_hello\",\n",
        "    operation_params = {\n",
        "        \"prompt\": \"Spanish\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HGiVjFSaNiL"
      },
      "source": [
        "### Create a controller\n",
        "\n",
        "The extension controller allows an application developer to specify which extensions to use.\n",
        "\n",
        "You'll create an extension controller that refers to the extension/tool that you created in the previous section:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSSqbpBpaNiL",
        "outputId": "5cc966c5-cbcb-4dc6-cf84-49bcf7b35c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "projects/964731510884/locations/us-central1/extensionControllers/6418192418956378112\n"
          ]
        }
      ],
      "source": [
        "# Define the extensions controller service client\n",
        "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
        "controller_client = llm_extension.extensions.services.extension_controller_service.client.ExtensionControllerServiceClient(\n",
        "    client_options=client_options)\n",
        "\n",
        "controller_spec = llm_extension.gapic.types.ExtensionControllerSpec()\n",
        "\n",
        "controller_req = llm_extension.gapic.types.ExtensionController()\n",
        "controller_req.display_name = \"Translate Extension Controller\"\n",
        "controller_req.description = \"Prints and translates hello in different languages\"\n",
        "controller_req.extension_controller_spec.extensions = [{\"extension\": extension_translate.resource_name}]\n",
        "\n",
        "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
        "\n",
        "controller_op = controller_client.create_extension_controller(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
        "    extension_controller=controller_req\n",
        ")\n",
        "controller = controller_op.result(timeout=300)\n",
        "print(controller.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxReDvQ_aNiL"
      },
      "source": [
        "### Use the controller in a query\n",
        "\n",
        "Now that you have an extension and an extension controller, you can start using the controller to answer queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgFGLmVQaNiL",
        "outputId": "bdaf9568-30ae-46d0-9c2d-71593d9e7b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response: \"Bonjour \"\n",
            "metadata {\n",
            "  steps {\n",
            "    thought: \"I should call translate_tool for this\"\n",
            "    extension_invoked: \"translate_tool\"\n",
            "    extension_instruction: \"return \\'bonjour\\' from the prompt \\'French\\'\"\n",
            "    response: \"{\\\"output\\\":\\\"bonjour\\\"}\"\n",
            "    success: true\n",
            "    error: \"\"\n",
            "  }\n",
            "  use_creativity: false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "execution_client = llm_extension.extensions.services.extension_controller_execution_service.client.ExtensionControllerExecutionServiceClient(\n",
        "    client_options=client_options\n",
        ")\n",
        "\n",
        "req = {\n",
        "    \"query\": {\n",
        "        \"query\": \"Question: how do I say 'hello' in French?\",\n",
        "    },\n",
        "    \"name\": controller.name,\n",
        "}\n",
        "\n",
        "response = execution_client.query(req)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c",
        "tags": []
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX",
        "outputId": "72fd74f8-2413-4cd1-af07-4eb9f55cfaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting Extension : projects/964731510884/locations/us-central1/extensions/3698299719001309184\n",
            "Delete Extension  backing LRO: projects/964731510884/locations/us-central1/operations/5234591172680220672\n",
            "Extension deleted. . Resource name: projects/964731510884/locations/us-central1/extensions/3698299719001309184\n"
          ]
        }
      ],
      "source": [
        "# Delete the controller\n",
        "op = controller_client.delete_extension_controller(name=controller.name)\n",
        "op.result()\n",
        "\n",
        "# Delete the extension\n",
        "extension_translate.delete()\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "#delete_bucket = False\n",
        "#if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "#! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m111",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}